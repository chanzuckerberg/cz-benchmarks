# CZ Benchmarks

## PROJECT STATUS: UNSTABLE

‚ö†Ô∏è **Warning:** Repository under active development and is in the alpha phase of development, subject to major refactors as outlined in the public-facing [roadmap](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/roadmap.md).

### What is cz-benchmarks?
cz-benchmarks is a package for standardized evaluation and comparison of machine learning models for biological applications (first, in the single-cell transcriptomics domain, with future plans to expand to additional domains). The package provides a toolkit for running containerized models, executing biologically-relevant tasks, and computing performance metrics. We see this tool as a step towards ensuring that large-scale AI models can be harnessed to deliver genuine biological insights -- by building trust, accelerating development, and bridging the gap between ML and biology communities.

### Why benchmarking? Why now?
Last year, CZI hosted a workshop focused on benchmarking and evaluation of AI models in biology, and the [insights gained](https://virtualcellmodels.cziscience.com/micro-pub/benchmarking-workshop) have reinforced our commitment to supporting the development of a robust benchmarking infrastructure, which we see as critical to achieving our Virtual Cell vision.

### üí¨ Community Feedback & Contributions
We're working to get the alpha version of cz-benchmarks stable to build with the community. In the meantime, for issues you may identify, feel free to open an issue on GitHub or reach out to us at [virtualcellmodels@chanzuckerberg.com](mailto:virtualcellmodels@chanzuckerberg.com).


## Table of contents

### Getting Started
- [Quick Start Guide](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/quick_start.md)

### How-To Guides
- [Add a Custom Dataset](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/how_to_guides/add_custom_dataset.md)
- [Add a Custom Model](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/how_to_guides/add_custom_model.md)
- [Add a New Metric](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/how_to_guides/add_new_metric.md)
- [Add a New Task](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/how_to_guides/add_new_task.md)
- [Interactive Mode](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/how_to_guides/interactive_mode.md)
- [Visualize Results](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/how_to_guides/visualize_results.md)

### Developer Guides
- [Datasets](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/developer_guides/datasets.md)
- [Metrics](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/developer_guides/metrics.md)
- [Models](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/developer_guides/models.md)
- [Tasks](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/developer_guides/tasks.md)
- [Debugging](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/developer_guides/debugging.md)
- [Writing Test](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/tests/README.md)
- [Writing Documentation](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/README.md)

### Policies
- [Assets](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/assets.md)
- [Governance](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/policy/definitions.md)
- [Code of Conduct](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/CODE_OF_CONDUCT.md)

### Additional Resources
- [Changelog & Release Notes](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/CHANGELOG.md)
- [Roadmap](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/docs/source/roadmap.md)
- [Legal](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/LICENSE.md)
- [Security](https://github.com/chanzuckerberg/cz-benchmarks/blob/main/SECURITY.md)